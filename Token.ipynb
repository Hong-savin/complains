{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926fb195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -okeh (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -okeh (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -okeh (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -okeh (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -okeh (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -okeh (c:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b79594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import sqlite3\n",
    "data = pd.read_csv(\"C:/Users/홍사빈/Desktop/archive/modified_data.csv\", low_memory=False)\n",
    "travel = csv.reader(data)\n",
    "next(travel)\n",
    "\n",
    "conn = pymysql.connect(host='127.0.0.1', port=3306,user='root',password='0000',db='mysql',charset='utf8')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58bf628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_12044\\615542492.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query,conn)\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM modified_data\"\n",
    "df = pd.read_sql_query(query,conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b44375e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# 바이트 객체를 문자열로 디코딩하고 sent_tokenize 함수를 적용하여 문장 분리\n",
    "sentences=df['Consumer complaint narrative'].apply(lambda x: sent_tokenize(x.decode('utf-8')))\n",
    "\n",
    "# 결과 출력\n",
    "#print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068693d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for idx, sentence in enumerate(sentences):\\n    print(f\"Sentence {idx + 1}: {sentence}\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#문장 토큰화\n",
    "# None 값을 가진 행을 제외하고 토큰화하여 리스트에 저장\n",
    "sentences = []\n",
    "for complaint in df['Consumer complaint narrative']:\n",
    "    if complaint is not None and complaint != \"None\":\n",
    "        if isinstance(complaint, bytes):\n",
    "            complaint = complaint.decode('utf-8')\n",
    "        # 문장을 토큰화하여 리스트에 추가\n",
    "        sentences.extend(sent_tokenize(complaint.replace('XXXX', ' ')))\n",
    "\n",
    "# 출력\n",
    "'''for idx, sentence in enumerate(sentences):\n",
    "    print(f\"Sentence {idx + 1}: {sentence}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee83823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for idx, word in enumerate(words):\\n    print(f\"Word {idx + 1}: {word}\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어 토큰화\n",
    "# None 값을 가진 행을 제외하고 토큰화하여 리스트에 저장\n",
    "words = []\n",
    "for complaint in df['Consumer complaint narrative']:\n",
    "    if complaint is not None and complaint != \"None\":\n",
    "        if isinstance(complaint, bytes):\n",
    "            complaint = complaint.decode('utf-8')\n",
    "        # 문장을 토큰화하여 단어로 분리하고 리스트에 추가\n",
    "        tokenized_words = word_tokenize(complaint.replace('XXXX', ' '))\n",
    "        words.extend(tokenized_words)\n",
    "\n",
    "# 출력\n",
    "'''for idx, word in enumerate(words):\n",
    "    print(f\"Word {idx + 1}: {word}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d1d5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식 토크나이저 생성\n",
    "tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
    "\n",
    "# 각 문장을 가져와서 'None'이 아닌 경우에만 토큰화하고 출력\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    if sentence != 'None':\n",
    "        # 문장을 토큰화하여 토큰 리스트로 변환\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        #print(f\"sentense {idx + 1} token:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a5d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 제거\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "# 불용어를 제거하고 출력\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    if sentence is not None and sentence != \"None\":  # None이 아닌 경우에만 처리\n",
    "        # 문장을 단어로 토큰화\n",
    "        words = word_tokenize(sentence)\n",
    "        # 불용어를 제거하고 새로운 단어 리스트 생성\n",
    "        filtered_words = [word for word in words if word.lower() not in stops]\n",
    "        # 불용어가 제거된 문장 출력\n",
    "        #print(f\"Sentence {idx + 1} without stopwords:\", ' '.join(filtered_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4bce3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
